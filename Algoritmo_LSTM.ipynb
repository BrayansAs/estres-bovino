{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaDJ6NbM4R4c"
   },
   "source": [
    "## Algoritmo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_sVYocgwqjC"
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "g8WDDqQaxRx4"
   },
   "outputs": [],
   "source": [
    "nombre_csv = 1\n",
    "de = pd.read_csv(f'Datos_entrenamiento/{nombre_csv}_e.csv')\n",
    "dp = pd.read_csv(f'Datos_prueba/{nombre_csv}_p.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNzDx458xTz5"
   },
   "outputs": [],
   "source": [
    "# Contamos las ocurrencias de cada nivel de estrés en la nueva columna\n",
    "conteo_nivel_estresde = de['Nivel_estres_1'].value_counts()\n",
    "conteo_nivel_estresdp = dp['Nivel_estres_1'].value_counts()\n",
    "# Mostramos el resultado\n",
    "print(conteo_nivel_estresde)\n",
    "print(conteo_nivel_estresdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xl9IHQwfxX6R"
   },
   "outputs": [],
   "source": [
    "# Crear un diccionario para mapear cada categoría única en la columna 'nivel_estres' a un número\n",
    "mapping = {'normal': 0, 'alerta': 1, 'peligro': 2}\n",
    "# Mapear las categorías a números utilizando el método map de pandas\n",
    "de['Nivel_estres_1'] = de['Nivel_estres_1'].map(mapping)\n",
    "dp['Nivel_estres_1'] = dp['Nivel_estres_1'].map(mapping)\n",
    "de['Nivel_estres_2'] = de['Nivel_estres_2'].map(mapping)\n",
    "dp['Nivel_estres_2'] = dp['Nivel_estres_2'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVUnOhfZ1Ntc"
   },
   "source": [
    "# ALGORITMO DE LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lvzb3Kfcxe5h"
   },
   "outputs": [],
   "source": [
    "# Separar características y etiquetas del conjunto de entrenamiento\n",
    "X_train = de[['period eating','period other','period resting','period rumination']]\n",
    "y_train = de['Nivel_estres_1']\n",
    "# Separar características y etiquetas del conjunto de prueba\n",
    "X_test = dp[['period eating','period other','period resting','period rumination']]\n",
    "y_test = dp['Nivel_estres_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separar características y etiquetas del conjunto de entrenamiento\n",
    "# X_train = de[['period eating_count','period other_count','period resting_count','period rumination_count']]\n",
    "# y_train = de['Nivel_estres_2']\n",
    "# # Separar características y etiquetas del conjunto de prueba\n",
    "# X_test = dp[['period eating_count','period other_count','period resting_count','period rumination_count']]\n",
    "# y_test = dp['Nivel_estres_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juQN7hSuxhmY"
   },
   "outputs": [],
   "source": [
    "# Estandarizar las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y48rGM_0xlNZ"
   },
   "outputs": [],
   "source": [
    "#Expandir a 24 horas de datos para capturar ciclo diario\n",
    "timesteps = 24\n",
    "X_train_reshaped = np.array([X_train_scaled[i:i + timesteps] for i in range(len(X_train_scaled) - timesteps)])\n",
    "y_train = y_train[timesteps:]\n",
    "X_test_reshaped = np.array([X_test_scaled[i:i + timesteps] for i in range(len(X_test_scaled) - timesteps)])\n",
    "y_test = y_test[timesteps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste de pesos: Calcular pesos de clase para manejar el desbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "#class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas a formato categórico\n",
    "y_train_categorical = to_categorical(y_train, num_classes=3)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weTv5z_TxnD4"
   },
   "outputs": [],
   "source": [
    "# Construir el modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(timesteps, X_train_scaled.shape[1])),LSTM(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy','auc'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_reshaped, y_train_categorical, epochs=50, batch_size=24,\n",
    "          validation_data=(X_test_reshaped, y_test_categorical), class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq-cWmEVxsKB",
    "outputId": "da098090-b3eb-42be-e96f-728e1712343b"
   },
   "outputs": [],
   "source": [
    "# Predecir las etiquetas para el conjunto de prueba\n",
    "y_pred_proba = model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "# Contamos las ocurrencias de cada nivel de estrés\n",
    "valores_unicos, conteos = np.unique(y_test, return_counts=True)\n",
    "valores_unicos1, conteos1 = np.unique(y_pred, return_counts=True)\n",
    "# Combina los valores únicos y sus conteos en un diccionario para facilitar la visualización\n",
    "ocurrencias = dict(zip(valores_unicos, conteos))\n",
    "ocurrenciaspre = dict(zip(valores_unicos1, conteos1))\n",
    "# Mostramos el resultado\n",
    "#print(conteo_nivel_estres)\n",
    "print(ocurrencias)\n",
    "print(ocurrenciaspre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_WwX96g31SC"
   },
   "source": [
    "# EVALUACION DEL ALGORITMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acuracy , test_auc = model.evaluate(X_test_reshaped, y_test_categorical)\n",
    "print(f\"Acuracy: {test_acuracy}\")\n",
    "print(f\"AUC en prueba: {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWISIj2Nx4KC",
    "outputId": "69dc4ea4-2114-458b-9b9b-093076faaf3e"
   },
   "outputs": [],
   "source": [
    "# EVALUACION DEL MODELO\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_pred2 = label_binarize(y_pred, classes=[0, 1, 2])\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# Calcular el AUC\n",
    "roc_auc = roc_auc_score(y_test_categorical, y_pred_proba, multi_class='ovo')\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_categorical[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Graficar las curvas ROC\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Extraer los valores\n",
    "values = roc_auc.values()\n",
    "# Calcular la media\n",
    "mean_auc = sum(values) / len(values)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'b--', label=f\"Mean AUC = {mean_auc:.2f}\", alpha=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC Multiclase')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig(f'../Curva_Roc/{nombre_csv}_roc_LSTM.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
