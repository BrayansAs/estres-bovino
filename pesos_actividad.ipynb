{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import prince  # Necesario para el análisis de correspondencias\n",
    "\n",
    "# Cargar los datos\n",
    "nombres_csv = {1,2,3,4,468,479,4003,4151,4160,4173}\n",
    "pca_pesos={}\n",
    "afc_pesos={}\n",
    "\n",
    "for nombre_csv in nombres_csv:\n",
    "    data = pd.read_csv(f'Data1_procesados/{nombre_csv}.csv')\n",
    "\n",
    "    # Definir la fecha límite y filtrar el DataFrame\n",
    "    fecha_limite = '2024-01-07'\n",
    "    df_7days = data[data['Fecha'] <= fecha_limite].copy()\n",
    "\n",
    "    # Normalizar los datos para PCA (sin 'Fecha' y 'Hora')\n",
    "    scaler = StandardScaler()\n",
    "    continue_data = df_7days[['period eating', 'period other', 'period resting', 'period rumination']]\n",
    "    continue_data_scaled = scaler.fit_transform(continue_data)\n",
    "\n",
    "    # Aplicar PCA para análisis de actividad\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(continue_data_scaled)\n",
    "\n",
    "    # Crear un DataFrame para los componentes principales\n",
    "    loadings = pca.components_.T\n",
    "    loadings_continue_data = pd.DataFrame(data=loadings, index=continue_data.columns, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "\n",
    "    # Calcular los pesos y el nivel de actividad basado en PCA\n",
    "    pca_weights = (loadings_continue_data['Principal Component 1'] + loadings_continue_data['Principal Component 2']) / 2\n",
    "    pca_pesos[nombre_csv]=pca_weights\n",
    "    activity_level = continue_data.dot(pca_weights)\n",
    "    # Añadir el nivel de actividad basado en PCA al DataFrame filtrado\n",
    "    df_7days['activity_level'] = activity_level\n",
    "\n",
    "    # Calcular y añadir el nivel de actividad (PCA) al DataFrame original `data`\n",
    "    data_continue = data[['period eating', 'period other', 'period resting', 'period rumination']]\n",
    "    data['activity_level'] = data_continue.dot(pca_weights)\n",
    "\n",
    "    # Paso adicional: Aplicar AFC en columnas de conteo\n",
    "    # Seleccionar solo las columnas de conteo para AFC\n",
    "    count_data = df_7days[['period eating_count', 'period other_count', 'period resting_count', 'period rumination_count']]\n",
    "\n",
    "    # Aplicar AFC\n",
    "    ca = prince.CA(n_components=2, n_iter=10)\n",
    "    ca = ca.fit(count_data)\n",
    "\n",
    "    # Obtener coordenadas de columnas (variables) para AFC\n",
    "    col_coords = ca.column_coordinates(count_data)\n",
    "\n",
    "    # Calcular los pesos de AFC para cada variable\n",
    "    afc_weights = (col_coords[0] + col_coords[1]) / 2\n",
    "    afc_weights.index = count_data.columns  # Asegurarse de que los índices coincidan con las columnas originales\n",
    "    afc_pesos[nombre_csv]=afc_weights\n",
    "    # Calcular el nivel de actividad basado en AFC\n",
    "    activity_level_2 = count_data.dot(afc_weights)\n",
    "    df_7days['activity_level_2'] = activity_level_2\n",
    "\n",
    "    # Calcular y añadir el nivel de actividad (AFC) al DataFrame original `data`\n",
    "    data_count = data[['period eating_count', 'period other_count', 'period resting_count', 'period rumination_count']]\n",
    "    data['activity_level_2'] = data_count.dot(afc_weights)\n",
    "\n",
    "    data.to_csv(f'Data1_actividad/{nombre_csv}_act.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "nombres_csv = {1,2,3,4,468,479,4003,4151,4160,4173}\n",
    "\n",
    "for nombre_csv in nombres_csv:\n",
    "    data = pd.read_csv(f'Data2_procesados/{nombre_csv}.csv')\n",
    "    # Calcular y añadir el nivel de actividad (PCA) al DataFrame original `data`\n",
    "    data_continue = data[['period eating', 'period other', 'period resting', 'period rumination']]\n",
    "    data['activity_level'] = data_continue.dot(pca_pesos[nombre_csv])\n",
    "\n",
    "\n",
    "    # Calcular y añadir el nivel de actividad (AFC) al DataFrame original `data`\n",
    "    data_count = data[['period eating_count', 'period other_count', 'period resting_count', 'period rumination_count']]\n",
    "    data['activity_level_2'] = data_count.dot(afc_pesos[nombre_csv])\n",
    "\n",
    "    data.to_csv(f'Data2_actividad/{nombre_csv}_act.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna datetime combinando 'Fecha' y 'Hora'\n",
    "df_7days['FechaHora'] = df_7days.apply(lambda row: pd.Timestamp(row['Fecha']) + pd.Timedelta(hours=row['Hora']), axis=1)\n",
    "\n",
    "# Asegurarse de que los datos estén ordenados por 'FechaHora'\n",
    "df_7days.sort_values('FechaHora', inplace=True)\n",
    "\n",
    "# Visualizar los resultados de PCA y AFC como gráficos de líneas\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(df_7days['FechaHora'], df_7days['activity_level'], marker='o', label='Nivel de Actividad (PCA)')\n",
    "plt.plot(df_7days['FechaHora'], df_7days['activity_level_2'], marker='x', label='Nivel de Actividad (AFC)')\n",
    "plt.xlabel('Fecha y Hora')\n",
    "plt.ylabel('Nivel de Actividad')\n",
    "plt.title('Nivel de Actividad por Fecha y Hora (PCA y AFC)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import prince\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def calculate_activity_levels(nombre_csv, input_path, output_path, fecha_limite='2024-01-07'):\n",
    "    \"\"\"\n",
    "    Calcula los niveles de actividad usando PCA y AFC con preprocesamiento mejorado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(f'{input_path}/{nombre_csv}.csv')\n",
    "        \n",
    "        # Verificar datos faltantes\n",
    "        if data.isnull().sum().any():\n",
    "            print(f\"Advertencia: Datos faltantes encontrados en {nombre_csv}\")\n",
    "            data = data.fillna(method='ffill')  # Forward fill para datos faltantes\n",
    "        \n",
    "        # Filtrar datos por fecha\n",
    "        df_7days = data[data['Fecha'] <= fecha_limite].copy()\n",
    "        \n",
    "        # Aplicar transformación para normalizar distribuciones sesgadas\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        \n",
    "        # Variables continuas\n",
    "        continue_vars = ['period eating', 'period other', 'period resting', 'period rumination']\n",
    "        continue_data = df_7days[continue_vars]\n",
    "        \n",
    "        # Usar RobustScaler para manejar outliers\n",
    "        scaler = RobustScaler()\n",
    "        continue_data_scaled = scaler.fit_transform(continue_data)\n",
    "        \n",
    "        # PCA con validación de varianza explicada\n",
    "        pca = PCA(n_components=2)\n",
    "        componen|ts = pca.fit_transform(continue_data_scaled)\n",
    "        \n",
    "        # Verificar varianza explicada\n",
    "        var_explained = pca.explained_variance_ratio_\n",
    "        print(f\"Varianza explicada por componentes PCA: {var_explained}\")\n",
    "        \n",
    "        # Calcular pesos PCA con umbral de contribución\n",
    "        loadings = pca.components_.T\n",
    "        loadings_df = pd.DataFrame(\n",
    "            data=loadings,\n",
    "            index=continue_vars,\n",
    "            columns=['PC1', 'PC2']\n",
    "        )\n",
    "        \n",
    "        # Pesos ponderados por varianza explicada\n",
    "        pca_weights = (loadings_df['PC1'] * var_explained[0] + \n",
    "                      loadings_df['PC2'] * var_explained[1]) / sum(var_explained)\n",
    "        \n",
    "        # Variables de conteo\n",
    "        count_vars = ['period eating_count', 'period other_count', \n",
    "                     'period resting_count', 'period rumination_count']\n",
    "        count_data = df_7days[count_vars]\n",
    "        \n",
    "        # AFC con validación\n",
    "        ca = prince.CA(\n",
    "            n_components=2,\n",
    "            n_iter=3,\n",
    "            random_state=42\n",
    "        )\n",
    "        ca.fit(count_data)\n",
    "        \n",
    "        # Validar calidad del AFC\n",
    "        print(f\"Inercia explicada AFC: {ca.explained_inertia_ratio_}\")\n",
    "        \n",
    "        # Obtener coordenadas y calcular pesos AFC\n",
    "        col_coords = ca.column_coordinates(count_data)\n",
    "        afc_weights = pd.Series(\n",
    "            (col_coords[0] * ca.explained_inertia_ratio_[0] +\n",
    "             col_coords[1] * ca.explained_inertia_ratio_[1]) / sum(ca.explained_inertia_ratio_),\n",
    "            index=count_vars\n",
    "        )\n",
    "        \n",
    "        # Calcular y agregar niveles de actividad al DataFrame original\n",
    "        data['activity_level'] = data[continue_vars].dot(pca_weights)\n",
    "        data['activity_level_2'] = data[count_vars].dot(afc_weights)\n",
    "        \n",
    "        # Normalizar los niveles de actividad\n",
    "        data['activity_level'] = (data['activity_level'] - data['activity_level'].mean()) / data['activity_level'].std()\n",
    "        data['activity_level_2'] = (data['activity_level_2'] - data['activity_level_2'].mean()) / data['activity_level_2'].std()\n",
    "        \n",
    "        # Guardar resultados\n",
    "        data.to_csv(f'{output_path}/{nombre_csv}_act.csv', index=False)\n",
    "        \n",
    "        return pca_weights, afc_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando archivo {nombre_csv}: {str(e)}\")\n",
    "        return None, None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
